{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTW Algorithm, Retrieval and Evaluation (Recall, precision, AP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pkl exists\n",
      "[270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 300, 301, 302, 303, 304]\n",
      "Starting masking and binarisation\n",
      "Loading binarised data from pkl\\270_words.pkl\n",
      "Page 270 done\n",
      "Loading binarised data from pkl\\271_words.pkl\n",
      "Page 271 done\n",
      "Loading binarised data from pkl\\272_words.pkl\n",
      "Page 272 done\n",
      "Loading binarised data from pkl\\273_words.pkl\n",
      "Page 273 done\n",
      "Loading binarised data from pkl\\274_words.pkl\n",
      "Page 274 done\n",
      "Loading binarised data from pkl\\275_words.pkl\n",
      "Page 275 done\n",
      "Loading binarised data from pkl\\276_words.pkl\n",
      "Page 276 done\n",
      "Loading binarised data from pkl\\277_words.pkl\n",
      "Page 277 done\n",
      "Loading binarised data from pkl\\278_words.pkl\n",
      "Page 278 done\n",
      "Loading binarised data from pkl\\279_words.pkl\n",
      "Page 279 done\n",
      "Loading binarised data from pkl\\300_words.pkl\n",
      "Page 300 done\n",
      "Loading binarised data from pkl\\301_words.pkl\n",
      "Page 301 done\n",
      "Loading binarised data from pkl\\302_words.pkl\n",
      "Page 302 done\n",
      "Loading binarised data from pkl\\303_words.pkl\n",
      "Page 303 done\n",
      "Loading binarised data from pkl\\304_words.pkl\n",
      "Page 304 done\n",
      "Data binarized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dictionary fusion: 100%|███████████████████████████████████████████████████████████████████████| 15/15 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary fusionned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalisation: 100%|█████████████████████████████████████████████████████████████| 3726/3726 [00:01<00:00, 2563.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing done\n",
      "Loading feature dictionary from pkl\\270_features.pkl\n",
      "Page 270 done\n",
      "Loading feature dictionary from pkl\\271_features.pkl\n",
      "Page 271 done\n",
      "Loading feature dictionary from pkl\\272_features.pkl\n",
      "Page 272 done\n",
      "Loading feature dictionary from pkl\\273_features.pkl\n",
      "Page 273 done\n",
      "Loading feature dictionary from pkl\\274_features.pkl\n",
      "Page 274 done\n",
      "Loading feature dictionary from pkl\\275_features.pkl\n",
      "Page 275 done\n",
      "Loading feature dictionary from pkl\\276_features.pkl\n",
      "Page 276 done\n",
      "Loading feature dictionary from pkl\\277_features.pkl\n",
      "Page 277 done\n",
      "Loading feature dictionary from pkl\\278_features.pkl\n",
      "Page 278 done\n",
      "Loading feature dictionary from pkl\\279_features.pkl\n",
      "Page 279 done\n",
      "Loading feature dictionary from pkl\\300_features.pkl\n",
      "Page 300 done\n",
      "Loading feature dictionary from pkl\\301_features.pkl\n",
      "Page 301 done\n",
      "Loading feature dictionary from pkl\\302_features.pkl\n",
      "Page 302 done\n",
      "Loading feature dictionary from pkl\\303_features.pkl\n",
      "Page 303 done\n",
      "Loading feature dictionary from pkl\\304_features.pkl\n",
      "Page 304 done\n",
      "Loading completed.\n"
     ]
    }
   ],
   "source": [
    "from FeatureVectors import load_images\n",
    "from FeatureVectors import getFeaturesMatrix\n",
    "results, numbers = load_images()\n",
    "allfeatures = getFeaturesMatrix(numbers, results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset and val_dataset created\n"
     ]
    }
   ],
   "source": [
    "# task folder locations\n",
    "dataset = os.path.join('..', 'dataset')\n",
    "task_fold = os.path.join(dataset, 'task')\n",
    "# training list\n",
    "train_f = open(os.path.join(task_fold, 'train.txt'), \"r\")\n",
    "train_list = []\n",
    "for l in train_f:\n",
    "    train_list.append(l[:3])\n",
    "# validation list\n",
    "val_f = open(os.path.join(task_fold, 'valid.txt'), \"r\")\n",
    "val_list = []\n",
    "for l in val_f:\n",
    "    val_list.append(l[:3])\n",
    "# create training and validation dataset\n",
    "train_dataset = {}\n",
    "val_dataset = {}\n",
    "for key in allfeatures.keys():\n",
    "    if key[:3] in train_list:\n",
    "        train_dataset[key] = allfeatures[key]\n",
    "    elif key[:3] in val_list:\n",
    "        val_dataset[key] = allfeatures[key]\n",
    "    else:\n",
    "        print(f'{key} is not included in training or validation dataset')\n",
    "\n",
    "print('train_dataset and val_dataset created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTW Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References :\n",
    "* [DTW from nikolasrieble](https://gist.github.com/nikolasrieble/8bd3a83e14c0b2fa66bfa2ddd8828717)\n",
    "* [Stackoverflow question](https://stackoverflow.com/questions/57015499/how-to-use-dynamic-time-warping-with-knn-in-python)\n",
    "* [tslearn.metrics](https://tslearn.readthedocs.io/en/latest/gen_modules/tslearn.metrics.html)\n",
    "* [R - DTW](http://dtw.r-forge.r-project.org/)\n",
    "* [dtw-python](https://pypi.org/project/dtw-python/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
